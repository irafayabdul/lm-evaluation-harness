# Boxes

### Paper

Title: `Entity Tracking in Language Models`

Abstract: `https://arxiv.org/abs/2305.02363`

Keeping track of how states of entities change as a text or dialog unfolds is a key prerequisite to discourse understanding.
Yet, there have been few systematic investigations into the ability of large language models (LLMs) to track discourse entities.
In this work, a task probing to what extent a language model can infer the final state of an entity given an English description
of the initial state and a series of state-changing operations is presented.

Homepage: `https://github.com/sebschu/entity-tracking-lms/tree/main`


### Citation

```
@inproceedings{kim-schuster-2023-entity,
    title = "Entity Tracking in Language Models",
    author = "Kim, Najoung  and
      Schuster, Sebastian",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023)",
    year = "2023",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.213",
    pages = "3835--3855"
}
```

### Groups and Tasks

#### Groups

* `boxes`

[//]: # (* : `Short description`)

#### Tasks

* `boxes-base`
* `boxes-altform`

[//]: # (* : `1-sentence description of what this particular task does`)

[//]: # (### Checklist)

[//]: # ()
[//]: # (For adding novel benchmarks/datasets to the library:)

[//]: # (* [ ] Is the task an existing benchmark in the literature?)

[//]: # (    * [ ] Have you referenced the original paper that introduced the task?)

[//]: # (    * [ ] If yes, does the original paper provide a reference implementation? If so, have you checked against the reference implementation and documented how to run such a test?)

[//]: # ()
[//]: # ()
[//]: # (If other tasks on this dataset are already supported:)

[//]: # (* [ ] Is the "Main" variant of this task clearly denoted?)

[//]: # (* [ ] Have you provided a short sentence in a README on what each new variant adds / evaluates?)

[//]: # (* [ ] Have you noted which, if any, published evaluation setups are matched by this variant?)
